#Configurations
env: development
data:
  batch_size: 128
  image_size: 224
  image_depth: 3
  dataset_folder: ./dataset/
  num_workers: 8
  shuffle: true
  use_random_horizontal_flip: true
  random_affine:
    degrees: 
      - -30
      - 30
    translate: 
      - 0.1
      - 0.3
    scale:
      - 0.1
      - 0.5
  color_jitter:
    brightness: 0.5
    hue: 0.25

model:
  model_save_folder: ./artifacts/train/
  model_save_freq: 2 #save every N epoch.
  N_saved_model_to_keep: 20 #keep the last N number of saved models and delete the earlier ones.
  model_name: vit-dog-breed
  encoder_transformer_depth: 8
  encoder_network_embedding_dim: 1024 #embedding dimension to be used throughout the transformer blocks in the encoder network.
  projection_keys_dim : 256
  projection_values_dim : 256
  mlp_ratio : 4 
  num_heads : 8
  attn_dropout_prob : 0.1
  feedforward_dropout_prob : 0.1

training:
  device : gpu
  load_checkpoint: true
  load_checkpoint_epoch: null
  start_epoch : 0
  end_epoch : 1000
  cosine_upper_bound_lr : 1.0e-4
  cosine_lower_bound_lr : 1.0e-6
  cosine_upper_bound_wd : 0.4
  cosine_lower_bound_wd : 0.04
  num_epoch_to_restart_lr : 5 #will be multiplied by iterations per epoch later since we're using the scale of steps for everything in the code.
  warmup_start_lr : 5.0e-6 #learning rate starts here.
  warmup_steps : 100 #iteration step. Not epoch step.
  use_bfloat16: true
  use_neptune: false
  use_tensorboar: true




